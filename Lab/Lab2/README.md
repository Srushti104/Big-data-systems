# Lab 2 - GCP- DataFlow,Datalab

In this lab, we will explore a structured dataset and then create training and evaluation datasets using Dataflow for a machine learning (ML) model.

__Dataflow__ is a managed service for executing a wide variety of data processing patterns. When you run your pipeline with the Cloud Dataflow service, the runner uploads your executable code and dependencies to a Google Cloud Storage bucket and creates a Cloud Dataflow job, which executes your pipeline on managed resources in Google Cloud Platform.[1](https://medium.com/google-cloud/basic-streaming-data-enrichment-on-google-cloud-with-dataflow-sql-a7684353119c)

__Datalab__ is used to explore, analyze, transform data and build Machine Learning (ML) models on Googleâ€™s Cloud virtual machine. 

__BigQuery__ is cloud-based big data analytics web service for processing very large read-only data sets, using SQL-like syntax.

## Lab completion date - 

## Setup:
 * Create an AWS account 
 * Install AWS CLI and configure
 * Create S3 bucket 
 * Python 3.7 
 * Boto3 - pip install boto3
 * Faker - from faker import Faker 
 * Random- import random (to generate a random file number)

## CodeLab document:
https://codelabs-preview.appspot.com/?file_id=1U5hDAUHTgloic_77oFvMeox299I9D2zWlN0fZhhgvIo#0
 

